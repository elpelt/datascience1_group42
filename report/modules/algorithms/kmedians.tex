The K-Medians cluster algorithm is also closely related to the K-Means algorithm, but is more robust to outliers, because it uses the median as statistics in order to determine the center of each cluster. Its main approach is to cluster data by minimizing the absolute deviations, corresponding to the Manhattan distance, between each point and its closest cluster center, i.e., creating $k$ disjoint cluster by minimizing the following function \cite{kmed}.
\begin{align}
    Q(\{\pi_j\}^K_{j=1}) = \sum_{j=1}^{K}\sum_{x \in \pi_j}||x-c_j||_1
\end{align}
The geometric median is used for the minimization.
\begin{align}
    {{arg\, min}\atop{y\in\mathbb{R}^n}} \sum_{i=1}^m ||x_i-y||_2
\end{align}
At the start of the algorithm, k cluster centers must be initialized. There are many different approaches to perform this task, such as Random Initialization, Density Analysis, Single Dimension Subsets, and many more \cite{kmed}. In this work, the random approach was used because many of the other theories, while theoretically promising, are inferior or nearly equivalent in performance to the results produced by random initialization \cite{kmed}. Achieving global optimization in K-Medians is known to be NP-complete \cite{kmed_time}.\\ 
The algorithm works as following \cite{algo_kmed}:
\begin{enumerate}
    \item Assign each datapoint to a cluster, i.e. its nearest cluster center using the Manhattan distance as default (it can be substituted for a different distance measure) 
    \item Shift the cluster centers to the position of the vector whose elements are equal to the median value of each dimension of all instances in a cluster
    \item There is no guarantee to get the perfect cluster because the starting cluster centers were initialized randomly. There is the approach of reinitializing the algorithm many times and securing the best cluster center of all iterations
\end{enumerate}
The runtime of the K-medians algorithm is, similarly to the K-Means algorithm, $O(ntk)$ with n being the number of points, t being the number of iterations needed for convergence and k being the number of clusters. Due to the algorithms similarity to the K-Means algorithm, the advantages and diadvantages apply here as well.\\
