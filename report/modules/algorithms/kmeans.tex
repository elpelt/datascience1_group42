% !TeX spellcheck = <none>
The K-means algorithm aims to group together similar items of a given dataset into clusters. 
The total number of clusters is predefined and represented as the value for k. All considered items can be referred to as points, as this clustering algorithm assumes an Euclidean space. Hence, only distance measures which assume an Eulicdean space, such as the Manhattan distance or the Euclidean distance, are sensibly appicable. The K-means algorithm belongs to the point-assignment algorithms in clustering, as all points are considered successively and assigned to the most fitting cluster. The algorithms operates in the following steps: \cite{MMDS}
\begin{enumerate}
	\item Initially, the algorithm picks k points whose positions each represent one cluster centroid
	\item All points are considered in turn:
	\begin{itemize}
		\item Find the nearest centroid of the considered point  using the Euclidean distance measure at default (but can be exchanged for a different distance measure)
		\item Assign point to cluster of that centroid
		\item Adapt the position of this centroid minimizing the Euclidean distances of the centroid to all datapoints of the cluster.
	\end{itemize}	
	
	\item (optional) fix all centroids and reassign all points with the inclusion of the initial k points
	
\end{enumerate}

The essential first step of initializing the clusters requires $k$ points that have a high chance of being in separate clusters. This can be achieved by different approaches . One possible approach consists of picking points which are as far away as possible from each other. This can be achieved by the conducting the following steps: \cite{MMDS}
\begin{enumerate}
	\item	A random point is picked as the first of $k$ cluster centorids
	\item	For k-1 passes: \\
	Pick the point whose minimum distance is the largest considering all previously chosen points
	
\end{enumerate}
Another way of determining the cluster centroids is the K++ initializer, described in section 5, which we used in our implementation of the K-means algorithm.\\
After the K-means algorithm assigned all points, an optional step of reassigning the points with fixed centroids can be conducted. This may be sensible since it is possible that after a point has been assigned to a cluster the centroids move so far that the point would now belong to a different cluster.\\
The average runtime of the K-means clustering algorithm is $O(ntk)$ where t is number of iteration the algorithm needs to converge \cite{scikit-learn-extra}.
The K-means clustering algorithm has many advantages including its simplicity which makes it easy to implement \cite{santini2016advantages}. However, a disadvantage is that the value for k might be difficult to determine. If a specific amount of cluster is needed however, the predetermination of k is an advantage. A further disadvantage is that the starting points of the centroids greatly effect the outcome of the algorithm. This means that the algorithm might have to be run multiple times.
